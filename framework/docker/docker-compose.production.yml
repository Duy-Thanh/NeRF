version: '3.8'

services:
  # Redis for persistent storage and job queuing
  redis:
    image: redis:7-alpine
    container_name: daf_redis_production
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
    networks:
      - daf_network

  # Production Coordinator with real HTTP and gRPC
  coordinator:
    build:
      context: ../..
      dockerfile: Dockerfile.production
    container_name: daf_coordinator_production
    restart: always
    ports:
      - "8080:8080"   # HTTP API
      - "50051:50051" # gRPC API
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - HTTP_PORT=8080
      - GRPC_PORT=50051
      - WORKER_TIMEOUT=300
      - JOB_PROCESSING_INTERVAL=2
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - coordinator_logs:/app/logs
    networks:
      - daf_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Production Worker with real gRPC client
  worker1:
    build:
      context: ../..
      dockerfile: Dockerfile.production.worker
    container_name: daf_worker1_production
    restart: always
    environment:
      - COORDINATOR_HOST=coordinator
      - COORDINATOR_PORT=50051
      - WORKER_ID=worker1
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MAX_CONCURRENT_TASKS=4
    depends_on:
      coordinator:
        condition: service_healthy
    volumes:
      - worker1_data:/app/data
      - worker1_logs:/app/logs
    networks:
      - daf_network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Additional workers for scaling
  worker2:
    build:
      context: ../..
      dockerfile: Dockerfile.production.worker
    container_name: daf_worker2_production
    restart: always
    environment:
      - COORDINATOR_HOST=coordinator
      - COORDINATOR_PORT=50051
      - WORKER_ID=worker2
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MAX_CONCURRENT_TASKS=4
    depends_on:
      coordinator:
        condition: service_healthy
    volumes:
      - worker2_data:/app/data
      - worker2_logs:/app/logs
    networks:
      - daf_network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  worker3:
    build:
      context: ../..
      dockerfile: Dockerfile.production.worker
    container_name: daf_worker3_production
    restart: always
    environment:
      - COORDINATOR_HOST=coordinator
      - COORDINATOR_PORT=50051
      - WORKER_ID=worker3
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MAX_CONCURRENT_TASKS=4
    depends_on:
      coordinator:
        condition: service_healthy
    volumes:
      - worker3_data:/app/data
      - worker3_logs:/app/logs
    networks:
      - daf_network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
          cpus: '0.5'

  # Optional: Monitoring and observability
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: daf_redis_ui
    restart: always
    ports:
      - "8081:8081"
    environment:
      - REDIS_HOSTS=local:redis:6379
    depends_on:
      - redis
    networks:
      - daf_network

  # Optional: Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    container_name: daf_nginx_production
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - nginx_logs:/var/log/nginx
    depends_on:
      - coordinator
    networks:
      - daf_network

volumes:
  redis_data:
    driver: local
  coordinator_logs:
    driver: local
  worker1_data:
    driver: local
  worker1_logs:
    driver: local
  worker2_data:
    driver: local
  worker2_logs:
    driver: local
  worker3_data:
    driver: local
  worker3_logs:
    driver: local
  nginx_logs:
    driver: local

networks:
  daf_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
